{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing Grid Search on keras, based on this <a href=\"https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\"> tutorial</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"test.csv\")\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ha\"] = np.where(df[\"ha\"].eq(\"h\"),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['opp_goal_difference_last', 'ha', 'opp_goal_difference_5MA', 'opp_goal_difference_10MA',\n",
    "       'since_last_win', 'goal_difference_5MA', 'goal_difference_10MA', 'goal_difference_last',\n",
    "        'yellow_cards_referee_hist','odds_5MA', 'odds_10MA', 'odds_last'\n",
    "       ]].values\n",
    "y = df[\"class_var\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = 1/y.value_counts()\n",
    "class_weights = (class_weights/np.sum(class_weights))*len(class_weights)\n",
    "class_weights = class_weights.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights[1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the dataset into train and test. We shuffle the examples as the order is not important here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "n_class_var = len(np.unique(y))\n",
    "\n",
    "y = keras.utils.to_categorical(y, num_classes=n_class_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We scale with the Standard Scaler. That is the features are normalized. Models usually work better when this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model's architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer=\"sgd\"):\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.Dense(\n",
    "                8, activation=\"relu\", input_shape=(X.shape[-1],)\n",
    "            ),\n",
    "            keras.layers.Dense(12, activation=\"relu\"),\n",
    "            keras.layers.Dropout(0.2),\n",
    "            keras.layers.Dense(8, activation=\"relu\"),\n",
    "            keras.layers.Dropout(0.2),\n",
    "            keras.layers.Dense(n_class_var, activation=\"softmax\")\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, stratify=y)\n",
    "\n",
    "model = create_model(\n",
    "    optimizer = keras.optimizers.SGD(\n",
    "        learning_rate=0.01, momentum=0.8, nesterov=False, name=\"SGD\"\n",
    "    )\n",
    ")\n",
    "history = model.fit(X_train, y_train, validation_split=0.1, batch_size=8, epochs=20, class_weight=class_weights)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "print(accuracy_score(np.argmax(y_test, axis=1), y_pred))\n",
    "\n",
    "print(classification_report(np.argmax(y_test, axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, stratify=y)\n",
    "\n",
    "model = create_model(optimizer=\"adam\")\n",
    "history = model.fit(X_train, y_train, validation_split=0.1, batch_size=8, epochs=10)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "print(accuracy_score(np.argmax(y_test, axis=1), y_pred))\n",
    "\n",
    "print(classification_report(np.argmax(y_test, axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "# define the grid search parameters\n",
    "batch_size = [1, 4, 8]\n",
    "epochs = [10, 20]\n",
    "optimizers = ['SGD', 'Adam']\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, optimizer=optimizers) \n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, verbose=3)\n",
    "grid_result = grid.fit(X, y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(grid.best_estimator_.predict(X_test), np.argmax(y_test, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
